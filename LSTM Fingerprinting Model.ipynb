{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "n_step = 100  # input data length, for 1 second data with sampling frequency 100Hz, n_step=100\n",
    "n_width = 3  # each sensor has 3 axes\n",
    "n_channel = 2  # 2 sensors\n",
    "n_hidden = 128  # hidden layer neuron. Recommended values 32, 64, 128\n",
    "\n",
    "# learning parameters\n",
    "learning_rate = 0.0025  # recommended values 0.0025, 0.005, 0.01\n",
    "l2_lambda = 0.002  # recommended values 0.00025, 0.0005, 0.001, 0.002\n",
    "dropout_prob = 0.5\n",
    "training_iters = 300  # 300 rounds\n",
    "batch_size = 200\n",
    "stop_loss = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Sturcture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_step, n_width, n_channel])\n",
    "y = tf.placeholder(\"float\", [None, n_class])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# define weights\n",
    "weights = {\n",
    "    # Hidden layer weights\n",
    "    'hidden': tf.Variable(tf.random_normal([n_width * n_channel, n_hidden]), name='weight_hidden'),\n",
    "    # 3*n_class inputs, n_class output(class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_class]), name='weight_out')\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden]), name='biases_hidden'),\n",
    "    'out': tf.Variable(tf.random_normal([n_class]), name='biases_out')\n",
    "}\n",
    "\n",
    "\n",
    "def stackLSTM(x, weights, biases, keep_prob):\n",
    "    with tf.variable_scope('trans'), tf.name_scope('trans'):\n",
    "        x_trans = tf.reshape(x, [-1, n_step, n_width * n_channel])\n",
    "        x_trans = tf.transpose(x_trans, [1, 0, 2])\n",
    "        x_trans = tf.reshape(x_trans, [-1, n_width * n_channel])\n",
    "        # Linear activation\n",
    "        x_act = tf.nn.relu(\n",
    "            tf.matmul(x_trans, weights['hidden']) + biases['hidden'])\n",
    "        # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "        x_split = tf.split(x_act, n_step, 0)\n",
    "    with tf.variable_scope('stack_LSTM'), tf.name_scope('stack_LSTM'):\n",
    "        # Define two stacked LSTM cells\n",
    "        lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(\n",
    "            n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "        lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(\n",
    "            n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "        lstm_cells = tf.contrib.rnn.MultiRNNCell(\n",
    "            [lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
    "        # Get LSTM cell output\n",
    "        outputs, states = tf.contrib.rnn.static_rnn(\n",
    "            lstm_cells, x_split, dtype=tf.float32)\n",
    "    with tf.variable_scope('output'), tf.name_scope('output'):\n",
    "        # Get last time step's output feature for a \"many to one\" style classifier\n",
    "        lstm_last_output = outputs[-1]\n",
    "        batchnorm = tf.contrib.layers.batch_norm(lstm_last_output)\n",
    "        dropout = tf.layers.dropout(batchnorm, rate=keep_prob)\n",
    "        out = tf.matmul(dropout, weights['out']) + biases['out']\n",
    "    return out\n",
    "\n",
    "\n",
    "pred = stackLSTM(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "regularization = l2_lambda * (tf.nn.l2_loss(\n",
    "    weights['hidden']) + tf.nn.l2_loss(weights['out']))\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=pred, labels=y)) + regularization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
