{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 说明\n",
    "\n",
    "1. 该代码使用`tensorflow-gpu` `v1.2.1`\n",
    "2. 本代码中有大量推荐参数，请先按照推荐参数排列组合进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "n_step = 100  # input data length, for 1 second data with sampling frequency 100Hz, n_step=100\n",
    "n_width = 3  # each sensor has 3 axes\n",
    "n_channel = 2  # 2 sensors\n",
    "n_hidden = 128  # hidden layer neuron. Recommended values 32, 64, 128\n",
    "\n",
    "# learning parameters\n",
    "learning_rate = 0.0025  # recommended values 0.0025, 0.005, 0.01\n",
    "l2_lambda = 0.002  # recommended values 0.00025, 0.0005, 0.001, 0.002\n",
    "dropout_prob = 0.5\n",
    "training_iters = 300  # 300 rounds\n",
    "batch_size = 200\n",
    "stop_loss = 0.15\n",
    "# directory to store log, including loss and grad_norm of generator and critic\n",
    "dir_mark = 'lstm_demo_model'\n",
    "log_dir = './log_sensor/' + dir_mark\n",
    "ckpt_dir = './ckpt_sensor/' + dir_mark\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Sturcture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_step, n_width, n_channel])\n",
    "y = tf.placeholder(\"float\", [None, n_class])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# define weights\n",
    "weights = {\n",
    "    # Hidden layer weights\n",
    "    'hidden': tf.Variable(tf.random_normal([n_width * n_channel, n_hidden]), name='weight_hidden'),\n",
    "    # 3*n_class inputs, n_class output(class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_class]), name='weight_out')\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden]), name='biases_hidden'),\n",
    "    'out': tf.Variable(tf.random_normal([n_class]), name='biases_out')\n",
    "}\n",
    "\n",
    "\n",
    "def stackLSTM(x, weights, biases, keep_prob):\n",
    "    with tf.variable_scope('trans'), tf.name_scope('trans'):\n",
    "        x_trans = tf.reshape(x, [-1, n_step, n_width * n_channel])\n",
    "        x_trans = tf.transpose(x_trans, [1, 0, 2])\n",
    "        x_trans = tf.reshape(x_trans, [-1, n_width * n_channel])\n",
    "        # Linear activation\n",
    "        x_act = tf.nn.relu(\n",
    "            tf.matmul(x_trans, weights['hidden']) + biases['hidden'])\n",
    "        # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "        x_split = tf.split(x_act, n_step, 0)\n",
    "    with tf.variable_scope('stack_LSTM'), tf.name_scope('stack_LSTM'):\n",
    "        # Define two stacked LSTM cells\n",
    "        lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(\n",
    "            n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "        lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(\n",
    "            n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "        lstm_cells = tf.contrib.rnn.MultiRNNCell(\n",
    "            [lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
    "        # Get LSTM cell output\n",
    "        outputs, states = tf.contrib.rnn.static_rnn(\n",
    "            lstm_cells, x_split, dtype=tf.float32)\n",
    "    with tf.variable_scope('output'), tf.name_scope('output'):\n",
    "        # Get last time step's output feature for a \"many to one\" style classifier\n",
    "        lstm_last_output = outputs[-1]\n",
    "        batchnorm = tf.contrib.layers.batch_norm(lstm_last_output)\n",
    "        dropout = tf.layers.dropout(batchnorm, rate=keep_prob)\n",
    "        out = tf.matmul(dropout, weights['out']) + biases['out']\n",
    "    return out\n",
    "\n",
    "\n",
    "pred = stackLSTM(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "regularization = l2_lambda * (tf.nn.l2_loss(\n",
    "    weights['hidden']) + tf.nn.l2_loss(weights['out']))\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=pred, labels=y)) + regularization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 训练过程设计\n",
    "\n",
    "```\n",
    "training_iters = 5000000*2 # 300 rounds\n",
    "batch_size = 200\n",
    "display_step = 10\n",
    "```\n",
    "step的上限是20000， 然而屏幕输出的上限是10000000\n",
    "\n",
    "- 每200步记录元信息，其它情况正常训练\n",
    "- 每10个step输出一次训练集的准确率\n",
    "- 当准确率高于0.95是，保存模型，停止训练\n",
    "- 每300个step输出测试集准确率\n",
    "- 每1000个step保存一下模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_all = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "# Launch the graph\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    summary_train_writer = tf.summary.FileWriter(\n",
    "        log_dir + '/train', sess.graph)\n",
    "    summary_test_writer = tf.summary.FileWriter(log_dir + '/test')\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        temp = (step - 1) * batch_size\n",
    "        bind = temp % trainSet_size\n",
    "        eind = (temp + batch_size) % trainSet_size\n",
    "        if (eind > bind):\n",
    "            batch_x = xx[bind: eind, :, :]\n",
    "            batch_y = yy[bind: eind, :]\n",
    "        else:\n",
    "            batch_x = np.vstack((xx[bind:, :, :], xx[:eind, :, :]))\n",
    "            batch_y = np.vstack((yy[bind:, :], yy[:eind, :]))\n",
    "        # Run optimization op (backprop)\n",
    "        if step % 200 == 0:\n",
    "            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "            run_metadata = tf.RunMetadata()\n",
    "            summary, _ = sess.run([merged_all, optimizer], feed_dict={x: batch_x, y: batch_y, keep_prob: dropout_prob},\n",
    "                                  options=run_options, run_metadata=run_metadata)\n",
    "            summary_train_writer.add_summary(summary, step)\n",
    "            summary_train_writer.add_run_metadata(\n",
    "                run_metadata, 'train_metadata {}'.format(step), step)\n",
    "\n",
    "        else:\n",
    "            summary, _ = sess.run([merged_all, optimizer], feed_dict={\n",
    "                                  x: batch_x, y: batch_y, keep_prob: dropout_prob})\n",
    "            summary_train_writer.add_summary(summary, step)\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                                 x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "            print(\"Iter \" + str(step * batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) +\n",
    "                  \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "            if loss <= stop_loss:\n",
    "                test_data = xx_test\n",
    "                test_label = yy_test\n",
    "                test_acc = sess.run(accuracy, feed_dict={\n",
    "                                    x: test_data, y: test_label, keep_prob: 1.})\n",
    "                print(\"Testing Accuracy:\", test_acc)\n",
    "                if test_acc >= 0.95:\n",
    "                    save_path = saver.save(\n",
    "                        sess, ckpt_dir + '/discriminator_birnn.model')\n",
    "                    print(\"model is saved at: %s\" % save_path)\n",
    "                    summary_train_writer.close()\n",
    "                    summary_test_writer.close()\n",
    "                    sess.close()\n",
    "        step += 1\n",
    "        if (step % 100 == 0):\n",
    "            summary, acc = sess.run([merged_all, accuracy], feed_dict={\n",
    "                                    x: xx_test, y: yy_test, keep_prob: 1.})\n",
    "            summary_test_writer.add_summary(summary, step)\n",
    "            print(\"Testing Accuracy:\", acc)\n",
    "        if (step % 1000 == 0):\n",
    "            save_path = saver.save(\n",
    "                sess, ckpt_dir + '/saver_lstm_tensorflow_' + str(step) + '.model')\n",
    "            print(\"model is saved at: %s\" % save_path)\n",
    "\n",
    "    summary_train_writer.close()\n",
    "    summary_test_writer.close()\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    test_data = xx_test\n",
    "    test_label = yy_test\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={\n",
    "          x: test_data, y: test_label, keep_prob: 1.}))\n",
    "\n",
    "    save_path = saver.save(\n",
    "        sess, ckpt_dir + '/saver_tensorflow_' + str(step) + '.model')\n",
    "    print(\"model is saved at: %s\" % save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
